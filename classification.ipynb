{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RYHRfGbO2iDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b777c5dc-26d2-4cec-af75-d7b1bfee618e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.core import Reshape, Flatten\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D, LSTM, MaxPooling1D, concatenate\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.initializers import RandomUniform, glorot_uniform\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from time import time\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import random\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_L9PNl32iDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from reader import Reader\n",
        "from keyphrase import Keyphrase\n",
        "from publication import Publication\n",
        "from wordembedder import Wordembedder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pw-_wN2D25Nq",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c1d30026-8d38-419f-f18a-b086f50f6b0d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c235455d-3f68-497c-97ad-2ce389fcaaa9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c235455d-3f68-497c-97ad-2ce389fcaaa9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data-classification.csv to data-classification.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rx8nYxbH2iDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0d218761-64ad-4b3a-df15-87eae7ccad1f"
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data-classification.csv')\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrases</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nuclear theory</td>\n",
              "      <td>Task</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thermalization</td>\n",
              "      <td>Task</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thermalization</td>\n",
              "      <td>Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>semi-classical methods</td>\n",
              "      <td>Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nuclear reactions</td>\n",
              "      <td>Process</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  phrases   labels\n",
              "0          Nuclear theory     Task\n",
              "1          thermalization     Task\n",
              "2          thermalization  Process\n",
              "3  semi-classical methods  Process\n",
              "4       nuclear reactions  Process"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "g_7HFPHn2iDj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(msg):\n",
        "    clean = [char for char in msg if char not in string.punctuation]\n",
        "    clean = ''.join(clean)\n",
        "    return clean.lower().split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "whsj1kNj2iDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a35c5804-7575-40eb-fb43-352cd75ba630"
      },
      "cell_type": "code",
      "source": [
        "maxlen = max([len(tokenize(p)) for p in data.phrases])\n",
        "print(maxlen)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-QNd2yF92iDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docs = data.phrases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P81oB1Qw2iDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(data['labels'])\n",
        "encoded_Y = encoder.transform(data['labels'])\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhBCnbkj2iDx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "we = Wordembedder(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUp8UIO42iD1",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1b5d1c7b-d7fc-4568-e4ed-cb1e44b9e264"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-152c7872-7a2c-4b61-bb13-a9c1db30f1fe\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-152c7872-7a2c-4b61-bb13-a9c1db30f1fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving embedding-matrix-classification.npy to embedding-matrix-classification.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7047hMB2iD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.load('embedding-matrix-classification.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGc3-ice4vki",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d6361f4f-4f7b-48fd-f3b3-ece9dce005ea"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-541205c6-3284-416a-8c08-63c3e538ef0b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-541205c6-3284-416a-8c08-63c3e538ef0b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving encoded-docs-classification.npy to encoded-docs-classification.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nh9B_WAJ5Umc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_docs = np.load('encoded-docs-classification.npy')\n",
        "vocab_size = 5379\n",
        "maxlen = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xooEIiN2iD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " x_train, x_test, y_train, y_test = train_test_split(encoded_docs, dummy_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GNFn61e2iEC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_conv_layers(num_filters, filter_sizes, embedding):\n",
        "    conv_layers = []\n",
        "    for s in filter_sizes:\n",
        "        conv = Conv1D(num_filters, s, activation='tanh', kernel_initializer=glorot_uniform(seed=random.seed(7)), kernel_regularizer=regularizers.l2(0.01))(embedding)\n",
        "        conv_layers.append(conv)\n",
        "    return conv_layers\n",
        "\n",
        "def max_pools(maxlen, filter_sizes, conv_layers):\n",
        "    pools = []\n",
        "    for i in range(len(conv_layers)):\n",
        "        pool = MaxPooling1D(maxlen - filter_sizes[i] + 1, strides=1)(conv_layers[i])\n",
        "        pools.append(pool)\n",
        "    return pools\n",
        "\n",
        "def create_cnn_model(filter_sizes, num_filters, embedding_matrix, embedding_dim, vocabulary_size, maxlen, num_classes):\n",
        "    filter_sizes = filter_sizes\n",
        "    num_filters = num_filters\n",
        "    drop = 0.5\n",
        "    \n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    embedding_layer = Embedding(vocabulary_size,\n",
        "                            embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=False)\n",
        "    embedding = embedding_layer(inputs)\n",
        "    \n",
        "    convs = create_conv_layers(num_filters, filter_sizes, embedding)\n",
        "    pools = max_pools(maxlen, filter_sizes, convs)\n",
        "    merged_tensor = concatenate(pools, axis=1)\n",
        "\n",
        "    flatten = Flatten()(merged_tensor)\n",
        "    \n",
        "    dense1 = Dense(128, kernel_initializer=RandomUniform(seed=random.seed(7)))(flatten)\n",
        "    dropout = Dropout(drop)(dense1)\n",
        "    \n",
        "    output = Dense(units=num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
        "    \n",
        "    # this creates a model that includes\n",
        "    model = Model(inputs, output)\n",
        "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "# def create_cnn_model():\n",
        "#     filter_sizes = filter_sizes\n",
        "#     num_filters = num_filters\n",
        "#     drop = 0.5\n",
        "    \n",
        "#     inputs = Input(shape=(maxlen,))\n",
        "#     embedding_layer = Embedding(vocabulary_size,\n",
        "#                             embedding_dim,\n",
        "#                             weights=[embedding_matrix],\n",
        "#                             trainable=True)\n",
        "#     embedding = embedding_layer(inputs)\n",
        "    \n",
        "#     convs = create_conv_layers(num_filters, filter_sizes, embedding)\n",
        "#     pools = max_pools(maxlen, filter_sizes, convs)\n",
        "#     merged_tensor = concatenate(pools, axis=1)\n",
        "\n",
        "#     flatten = Flatten()(merged_tensor)\n",
        "    \n",
        "#     dense1 = Dense(128, kernel_initializer=RandomUniform(seed=random.seed(7)))(flatten)\n",
        "#     dropout = Dropout(drop)(dense1)\n",
        "    \n",
        "#     output = Dense(units=num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
        "    \n",
        "#     # this creates a model that includes\n",
        "#     model = Model(inputs, output)\n",
        "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     print(model.summary())\n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKvt_GBC2iEG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fit_and_evaluate(x_train, y_train, x_val, y_val, x_test, y_test, epochs, filepath):\n",
        "    model = None\n",
        "    model = create_cnn_model([1,2], 128, embedding_matrix, 300, vocab_size, maxlen, 3)\n",
        "    adam = Adam(lr=1e-3)\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
        "              optimizer=adam)\n",
        "    callbacks = [EarlyStopping(patience=4),\n",
        "            ModelCheckpoint(filepath=filepath, save_best_only=True)]\n",
        "    results = model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_data= (x_val,y_val),\n",
        "                        callbacks=callbacks, verbose=1)\n",
        "    metrics = model.evaluate(x_test, y_test)\n",
        "    loss = metrics[0]\n",
        "    accuracy = metrics[1]\n",
        "    return results, model, loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lv-NhmVJ5jY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = 'model/model-cnn.h5'\n",
        "path_best = 'model/model-cnn-cv.h5'\n",
        "path_dir = os.path.dirname(path)\n",
        "path_best_dir = os.path.dirname(path_best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ctMRnUg2iEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8959
        },
        "outputId": "801a75b0-f1be-44aa-efb0-89ace47e1c4d"
      },
      "cell_type": "code",
      "source": [
        "kfold = KFold(10, True, random_state=7)\n",
        "\n",
        "#save the model history in a list after fitting so that we can plot later\n",
        "model_history = [] \n",
        "\n",
        "table_cnn = []\n",
        "\n",
        "i=0\n",
        "\n",
        "for t, v in kfold.split(x_train, y_train):\n",
        "    print(\"Training on Fold: \",i+1)\n",
        "    t_x = x_train[t]\n",
        "    val_x = x_train[v]\n",
        "    t_y = y_train[t]\n",
        "    val_y = y_train[v]\n",
        "    \n",
        "    history, cnn_model, loss, accuracy = fit_and_evaluate(t_x, t_y, val_x, val_y, x_test, y_test, 100, path_dir)\n",
        "    model_history.append(history)\n",
        "    \n",
        "    y_pred = cnn_model.predict(x_test)\n",
        "    \n",
        "    table_cnn += [[loss, accuracy]]\n",
        "    i+=1"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on Fold:  1\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_24 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_24 (Embedding)        (None, 25, 300)      1613700     input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_49 (Conv1D)              (None, 25, 128)      38528       embedding_24[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_50 (Conv1D)              (None, 24, 128)      76928       embedding_24[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_49 (MaxPooling1D) (None, 1, 128)       0           conv1d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_50 (MaxPooling1D) (None, 1, 128)       0           conv1d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 2, 128)       0           max_pooling1d_49[0][0]           \n",
            "                                                                 max_pooling1d_50[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 256)          0           concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 128)          32896       flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 128)          0           dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 3)            387         dropout_21[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4846 samples, validate on 539 samples\n",
            "Epoch 1/100\n",
            "4846/4846 [==============================] - 6s 1ms/step - loss: 2.0954 - acc: 0.5986 - val_loss: 1.0460 - val_acc: 0.6438\n",
            "Epoch 2/100\n",
            "4846/4846 [==============================] - 3s 556us/step - loss: 0.9266 - acc: 0.6791 - val_loss: 0.8690 - val_acc: 0.6957\n",
            "Epoch 3/100\n",
            "4846/4846 [==============================] - 3s 544us/step - loss: 0.8281 - acc: 0.6991 - val_loss: 0.8391 - val_acc: 0.6790\n",
            "Epoch 4/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.7909 - acc: 0.7181 - val_loss: 0.8203 - val_acc: 0.6772\n",
            "Epoch 5/100\n",
            "4846/4846 [==============================] - 3s 551us/step - loss: 0.7624 - acc: 0.7288 - val_loss: 0.8306 - val_acc: 0.6920\n",
            "Epoch 6/100\n",
            "4846/4846 [==============================] - 3s 550us/step - loss: 0.7459 - acc: 0.7385 - val_loss: 0.8321 - val_acc: 0.6716\n",
            "Epoch 7/100\n",
            "4846/4846 [==============================] - 3s 560us/step - loss: 0.7234 - acc: 0.7507 - val_loss: 0.8414 - val_acc: 0.6846\n",
            "Epoch 8/100\n",
            "4846/4846 [==============================] - 3s 557us/step - loss: 0.6983 - acc: 0.7716 - val_loss: 0.8329 - val_acc: 0.6939\n",
            "1347/1347 [==============================] - 0s 234us/step\n",
            "Training on Fold:  2\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_25 (Embedding)        (None, 25, 300)      1613700     input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_51 (Conv1D)              (None, 25, 128)      38528       embedding_25[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_52 (Conv1D)              (None, 24, 128)      76928       embedding_25[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_51 (MaxPooling1D) (None, 1, 128)       0           conv1d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_52 (MaxPooling1D) (None, 1, 128)       0           conv1d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 2, 128)       0           max_pooling1d_51[0][0]           \n",
            "                                                                 max_pooling1d_52[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_22 (Flatten)            (None, 256)          0           concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 128)          32896       flatten_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 128)          0           dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 3)            387         dropout_22[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4846 samples, validate on 539 samples\n",
            "Epoch 1/100\n",
            "4846/4846 [==============================] - 6s 1ms/step - loss: 2.1298 - acc: 0.5995 - val_loss: 1.0851 - val_acc: 0.6642\n",
            "Epoch 2/100\n",
            "4846/4846 [==============================] - 3s 550us/step - loss: 0.9352 - acc: 0.6878 - val_loss: 0.8820 - val_acc: 0.6568\n",
            "Epoch 3/100\n",
            "4846/4846 [==============================] - 3s 565us/step - loss: 0.8274 - acc: 0.6950 - val_loss: 0.8619 - val_acc: 0.6660\n",
            "Epoch 4/100\n",
            "4846/4846 [==============================] - 3s 555us/step - loss: 0.7865 - acc: 0.7064 - val_loss: 0.8232 - val_acc: 0.6976\n",
            "Epoch 5/100\n",
            "4846/4846 [==============================] - 3s 550us/step - loss: 0.7655 - acc: 0.7251 - val_loss: 0.8360 - val_acc: 0.6753\n",
            "Epoch 6/100\n",
            "4846/4846 [==============================] - 3s 550us/step - loss: 0.7403 - acc: 0.7402 - val_loss: 0.8632 - val_acc: 0.6846\n",
            "Epoch 7/100\n",
            "4846/4846 [==============================] - 3s 558us/step - loss: 0.7323 - acc: 0.7472 - val_loss: 0.8376 - val_acc: 0.6642\n",
            "Epoch 8/100\n",
            "4846/4846 [==============================] - 3s 558us/step - loss: 0.7142 - acc: 0.7668 - val_loss: 0.8436 - val_acc: 0.7013\n",
            "1347/1347 [==============================] - 0s 233us/step\n",
            "Training on Fold:  3\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_26 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_26 (Embedding)        (None, 25, 300)      1613700     input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_53 (Conv1D)              (None, 25, 128)      38528       embedding_26[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_54 (Conv1D)              (None, 24, 128)      76928       embedding_26[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_53 (MaxPooling1D) (None, 1, 128)       0           conv1d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_54 (MaxPooling1D) (None, 1, 128)       0           conv1d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 2, 128)       0           max_pooling1d_53[0][0]           \n",
            "                                                                 max_pooling1d_54[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_23 (Flatten)            (None, 256)          0           concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 128)          32896       flatten_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 128)          0           dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 3)            387         dropout_23[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4846 samples, validate on 539 samples\n",
            "Epoch 1/100\n",
            "4846/4846 [==============================] - 6s 1ms/step - loss: 2.0936 - acc: 0.5991 - val_loss: 1.0371 - val_acc: 0.6883\n",
            "Epoch 2/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.9188 - acc: 0.6863 - val_loss: 0.8541 - val_acc: 0.6883\n",
            "Epoch 3/100\n",
            "4846/4846 [==============================] - 3s 540us/step - loss: 0.8254 - acc: 0.6944 - val_loss: 0.8362 - val_acc: 0.6772\n",
            "Epoch 4/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.7799 - acc: 0.7175 - val_loss: 0.8280 - val_acc: 0.6586\n",
            "Epoch 5/100\n",
            "4846/4846 [==============================] - 3s 546us/step - loss: 0.7571 - acc: 0.7280 - val_loss: 0.8134 - val_acc: 0.6865\n",
            "Epoch 6/100\n",
            "4846/4846 [==============================] - 3s 547us/step - loss: 0.7363 - acc: 0.7423 - val_loss: 0.8021 - val_acc: 0.6994\n",
            "Epoch 7/100\n",
            "4846/4846 [==============================] - 3s 554us/step - loss: 0.7233 - acc: 0.7497 - val_loss: 0.8470 - val_acc: 0.6827\n",
            "Epoch 8/100\n",
            "4846/4846 [==============================] - 3s 551us/step - loss: 0.6975 - acc: 0.7662 - val_loss: 0.8344 - val_acc: 0.6994\n",
            "Epoch 9/100\n",
            "4846/4846 [==============================] - 3s 553us/step - loss: 0.6920 - acc: 0.7716 - val_loss: 0.8331 - val_acc: 0.6883\n",
            "Epoch 10/100\n",
            "4846/4846 [==============================] - 3s 548us/step - loss: 0.6615 - acc: 0.7980 - val_loss: 0.8806 - val_acc: 0.6790\n",
            "1347/1347 [==============================] - 0s 229us/step\n",
            "Training on Fold:  4\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_27 (Embedding)        (None, 25, 300)      1613700     input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_55 (Conv1D)              (None, 25, 128)      38528       embedding_27[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_56 (Conv1D)              (None, 24, 128)      76928       embedding_27[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_55 (MaxPooling1D) (None, 1, 128)       0           conv1d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_56 (MaxPooling1D) (None, 1, 128)       0           conv1d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 2, 128)       0           max_pooling1d_55[0][0]           \n",
            "                                                                 max_pooling1d_56[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_24 (Flatten)            (None, 256)          0           concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 128)          32896       flatten_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 128)          0           dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 3)            387         dropout_24[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4846 samples, validate on 539 samples\n",
            "Epoch 1/100\n",
            "4846/4846 [==============================] - 6s 1ms/step - loss: 2.1757 - acc: 0.5974 - val_loss: 1.0781 - val_acc: 0.6642\n",
            "Epoch 2/100\n",
            "4846/4846 [==============================] - 3s 543us/step - loss: 0.9341 - acc: 0.6729 - val_loss: 0.8522 - val_acc: 0.7069\n",
            "Epoch 3/100\n",
            "4846/4846 [==============================] - 3s 547us/step - loss: 0.8226 - acc: 0.7037 - val_loss: 0.8223 - val_acc: 0.6642\n",
            "Epoch 4/100\n",
            "4846/4846 [==============================] - 3s 554us/step - loss: 0.7824 - acc: 0.7117 - val_loss: 0.8618 - val_acc: 0.6660\n",
            "Epoch 5/100\n",
            "4846/4846 [==============================] - 3s 562us/step - loss: 0.7679 - acc: 0.7253 - val_loss: 0.8202 - val_acc: 0.6976\n",
            "Epoch 6/100\n",
            "4846/4846 [==============================] - 3s 555us/step - loss: 0.7438 - acc: 0.7404 - val_loss: 0.8077 - val_acc: 0.7161\n",
            "Epoch 7/100\n",
            "4846/4846 [==============================] - 3s 553us/step - loss: 0.7251 - acc: 0.7431 - val_loss: 0.8046 - val_acc: 0.6976\n",
            "Epoch 8/100\n",
            "4846/4846 [==============================] - 3s 558us/step - loss: 0.7059 - acc: 0.7567 - val_loss: 0.8223 - val_acc: 0.6939\n",
            "Epoch 9/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.6854 - acc: 0.7790 - val_loss: 0.8519 - val_acc: 0.6698\n",
            "Epoch 10/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.6846 - acc: 0.7757 - val_loss: 0.8682 - val_acc: 0.6735\n",
            "Epoch 11/100\n",
            "4846/4846 [==============================] - 3s 556us/step - loss: 0.6700 - acc: 0.7823 - val_loss: 0.8460 - val_acc: 0.6957\n",
            "1347/1347 [==============================] - 0s 233us/step\n",
            "Training on Fold:  5\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_28 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_28 (Embedding)        (None, 25, 300)      1613700     input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_57 (Conv1D)              (None, 25, 128)      38528       embedding_28[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_58 (Conv1D)              (None, 24, 128)      76928       embedding_28[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_57 (MaxPooling1D) (None, 1, 128)       0           conv1d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_58 (MaxPooling1D) (None, 1, 128)       0           conv1d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 2, 128)       0           max_pooling1d_57[0][0]           \n",
            "                                                                 max_pooling1d_58[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_25 (Flatten)            (None, 256)          0           concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 128)          32896       flatten_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 128)          0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 3)            387         dropout_25[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4846 samples, validate on 539 samples\n",
            "Epoch 1/100\n",
            "4846/4846 [==============================] - 6s 1ms/step - loss: 2.1659 - acc: 0.5951 - val_loss: 1.0737 - val_acc: 0.6883\n",
            "Epoch 2/100\n",
            "4846/4846 [==============================] - 3s 556us/step - loss: 0.9396 - acc: 0.6723 - val_loss: 0.8432 - val_acc: 0.6753\n",
            "Epoch 3/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.8357 - acc: 0.6927 - val_loss: 0.8218 - val_acc: 0.6976\n",
            "Epoch 4/100\n",
            "4846/4846 [==============================] - 3s 553us/step - loss: 0.7887 - acc: 0.7140 - val_loss: 0.8355 - val_acc: 0.6827\n",
            "Epoch 5/100\n",
            "4846/4846 [==============================] - 3s 557us/step - loss: 0.7686 - acc: 0.7189 - val_loss: 0.7957 - val_acc: 0.6994\n",
            "Epoch 6/100\n",
            "4846/4846 [==============================] - 3s 540us/step - loss: 0.7488 - acc: 0.7344 - val_loss: 0.7806 - val_acc: 0.7273\n",
            "Epoch 7/100\n",
            "4846/4846 [==============================] - 3s 549us/step - loss: 0.7215 - acc: 0.7480 - val_loss: 0.8303 - val_acc: 0.7050\n",
            "Epoch 8/100\n",
            "4846/4846 [==============================] - 3s 560us/step - loss: 0.7218 - acc: 0.7557 - val_loss: 0.8662 - val_acc: 0.6902\n",
            "Epoch 9/100\n",
            "4846/4846 [==============================] - 3s 554us/step - loss: 0.7057 - acc: 0.7662 - val_loss: 0.8158 - val_acc: 0.7069\n",
            "Epoch 10/100\n",
            "4846/4846 [==============================] - 3s 548us/step - loss: 0.6819 - acc: 0.7889 - val_loss: 0.8093 - val_acc: 0.6994\n",
            "1347/1347 [==============================] - 0s 228us/step\n",
            "Training on Fold:  6\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_29 (Embedding)        (None, 25, 300)      1613700     input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_59 (Conv1D)              (None, 25, 128)      38528       embedding_29[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_60 (Conv1D)              (None, 24, 128)      76928       embedding_29[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_59 (MaxPooling1D) (None, 1, 128)       0           conv1d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_60 (MaxPooling1D) (None, 1, 128)       0           conv1d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 2, 128)       0           max_pooling1d_59[0][0]           \n",
            "                                                                 max_pooling1d_60[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_26 (Flatten)            (None, 256)          0           concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 128)          32896       flatten_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 128)          0           dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 3)            387         dropout_26[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4847 samples, validate on 538 samples\n",
            "Epoch 1/100\n",
            "4847/4847 [==============================] - 6s 1ms/step - loss: 2.1496 - acc: 0.5946 - val_loss: 1.0501 - val_acc: 0.6710\n",
            "Epoch 2/100\n",
            "4847/4847 [==============================] - 3s 563us/step - loss: 0.9316 - acc: 0.6802 - val_loss: 0.8555 - val_acc: 0.7045\n",
            "Epoch 3/100\n",
            "4847/4847 [==============================] - 3s 543us/step - loss: 0.8240 - acc: 0.7033 - val_loss: 0.8147 - val_acc: 0.6989\n",
            "Epoch 4/100\n",
            "4847/4847 [==============================] - 3s 554us/step - loss: 0.7868 - acc: 0.7186 - val_loss: 0.8023 - val_acc: 0.7007\n",
            "Epoch 5/100\n",
            "4847/4847 [==============================] - 3s 557us/step - loss: 0.7605 - acc: 0.7264 - val_loss: 0.8634 - val_acc: 0.6487\n",
            "Epoch 6/100\n",
            "4847/4847 [==============================] - 3s 544us/step - loss: 0.7499 - acc: 0.7312 - val_loss: 0.8404 - val_acc: 0.6840\n",
            "Epoch 7/100\n",
            "4847/4847 [==============================] - 3s 545us/step - loss: 0.7351 - acc: 0.7400 - val_loss: 0.8164 - val_acc: 0.6970\n",
            "Epoch 8/100\n",
            "4847/4847 [==============================] - 3s 545us/step - loss: 0.7056 - acc: 0.7687 - val_loss: 0.9027 - val_acc: 0.6561\n",
            "1347/1347 [==============================] - 0s 228us/step\n",
            "Training on Fold:  7\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_30 (Embedding)        (None, 25, 300)      1613700     input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_61 (Conv1D)              (None, 25, 128)      38528       embedding_30[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_62 (Conv1D)              (None, 24, 128)      76928       embedding_30[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_61 (MaxPooling1D) (None, 1, 128)       0           conv1d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_62 (MaxPooling1D) (None, 1, 128)       0           conv1d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 2, 128)       0           max_pooling1d_61[0][0]           \n",
            "                                                                 max_pooling1d_62[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_27 (Flatten)            (None, 256)          0           concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 128)          32896       flatten_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 128)          0           dense_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 3)            387         dropout_27[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4847 samples, validate on 538 samples\n",
            "Epoch 1/100\n",
            "4847/4847 [==============================] - 6s 1ms/step - loss: 2.1152 - acc: 0.5938 - val_loss: 1.0500 - val_acc: 0.6896\n",
            "Epoch 2/100\n",
            "4847/4847 [==============================] - 3s 558us/step - loss: 0.9263 - acc: 0.6808 - val_loss: 0.8639 - val_acc: 0.7063\n",
            "Epoch 3/100\n",
            "4847/4847 [==============================] - 3s 560us/step - loss: 0.8320 - acc: 0.6909 - val_loss: 0.8284 - val_acc: 0.7156\n",
            "Epoch 4/100\n",
            "4847/4847 [==============================] - 3s 571us/step - loss: 0.7926 - acc: 0.7138 - val_loss: 0.8446 - val_acc: 0.6729\n",
            "Epoch 5/100\n",
            "4847/4847 [==============================] - 3s 558us/step - loss: 0.7623 - acc: 0.7221 - val_loss: 0.8266 - val_acc: 0.6952\n",
            "Epoch 6/100\n",
            "4847/4847 [==============================] - 3s 550us/step - loss: 0.7471 - acc: 0.7328 - val_loss: 0.8523 - val_acc: 0.6729\n",
            "Epoch 7/100\n",
            "4847/4847 [==============================] - 3s 573us/step - loss: 0.7248 - acc: 0.7512 - val_loss: 0.8474 - val_acc: 0.6933\n",
            "Epoch 8/100\n",
            "4847/4847 [==============================] - 3s 579us/step - loss: 0.7047 - acc: 0.7627 - val_loss: 0.8662 - val_acc: 0.7082\n",
            "Epoch 9/100\n",
            "4847/4847 [==============================] - 3s 581us/step - loss: 0.6941 - acc: 0.7687 - val_loss: 0.8451 - val_acc: 0.6989\n",
            "1347/1347 [==============================] - 0s 255us/step\n",
            "Training on Fold:  8\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_31 (Embedding)        (None, 25, 300)      1613700     input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_63 (Conv1D)              (None, 25, 128)      38528       embedding_31[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_64 (Conv1D)              (None, 24, 128)      76928       embedding_31[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_63 (MaxPooling1D) (None, 1, 128)       0           conv1d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_64 (MaxPooling1D) (None, 1, 128)       0           conv1d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 2, 128)       0           max_pooling1d_63[0][0]           \n",
            "                                                                 max_pooling1d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_28 (Flatten)            (None, 256)          0           concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 128)          32896       flatten_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 128)          0           dense_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 3)            387         dropout_28[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4847 samples, validate on 538 samples\n",
            "Epoch 1/100\n",
            "4847/4847 [==============================] - 6s 1ms/step - loss: 2.1376 - acc: 0.6132 - val_loss: 1.1193 - val_acc: 0.6468\n",
            "Epoch 2/100\n",
            "4847/4847 [==============================] - 3s 560us/step - loss: 0.9410 - acc: 0.6866 - val_loss: 0.8617 - val_acc: 0.7100\n",
            "Epoch 3/100\n",
            "4847/4847 [==============================] - 3s 556us/step - loss: 0.8302 - acc: 0.6967 - val_loss: 0.8529 - val_acc: 0.7045\n",
            "Epoch 4/100\n",
            "4847/4847 [==============================] - 3s 558us/step - loss: 0.7898 - acc: 0.7190 - val_loss: 0.8275 - val_acc: 0.7063\n",
            "Epoch 5/100\n",
            "4847/4847 [==============================] - 3s 556us/step - loss: 0.7656 - acc: 0.7256 - val_loss: 0.8293 - val_acc: 0.6840\n",
            "Epoch 6/100\n",
            "4847/4847 [==============================] - 3s 549us/step - loss: 0.7399 - acc: 0.7343 - val_loss: 0.8247 - val_acc: 0.6933\n",
            "Epoch 7/100\n",
            "4847/4847 [==============================] - 3s 556us/step - loss: 0.7239 - acc: 0.7535 - val_loss: 0.8368 - val_acc: 0.7026\n",
            "Epoch 8/100\n",
            "4847/4847 [==============================] - 3s 561us/step - loss: 0.7061 - acc: 0.7605 - val_loss: 0.8563 - val_acc: 0.6989\n",
            "Epoch 9/100\n",
            "4847/4847 [==============================] - 3s 553us/step - loss: 0.6850 - acc: 0.7733 - val_loss: 0.8204 - val_acc: 0.7119\n",
            "Epoch 10/100\n",
            "4847/4847 [==============================] - 3s 558us/step - loss: 0.6653 - acc: 0.7912 - val_loss: 0.8549 - val_acc: 0.7119\n",
            "Epoch 11/100\n",
            "4847/4847 [==============================] - 3s 562us/step - loss: 0.6551 - acc: 0.8015 - val_loss: 0.8624 - val_acc: 0.7026\n",
            "Epoch 12/100\n",
            "4847/4847 [==============================] - 3s 557us/step - loss: 0.6182 - acc: 0.8230 - val_loss: 0.8566 - val_acc: 0.7045\n",
            "Epoch 13/100\n",
            "4847/4847 [==============================] - 3s 564us/step - loss: 0.6179 - acc: 0.8279 - val_loss: 0.8812 - val_acc: 0.7230\n",
            "1347/1347 [==============================] - 0s 239us/step\n",
            "Training on Fold:  9\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_32 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_32 (Embedding)        (None, 25, 300)      1613700     input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_65 (Conv1D)              (None, 25, 128)      38528       embedding_32[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_66 (Conv1D)              (None, 24, 128)      76928       embedding_32[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_65 (MaxPooling1D) (None, 1, 128)       0           conv1d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_66 (MaxPooling1D) (None, 1, 128)       0           conv1d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 2, 128)       0           max_pooling1d_65[0][0]           \n",
            "                                                                 max_pooling1d_66[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_29 (Flatten)            (None, 256)          0           concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 128)          32896       flatten_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 128)          0           dense_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 3)            387         dropout_29[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4847 samples, validate on 538 samples\n",
            "Epoch 1/100\n",
            "4847/4847 [==============================] - 7s 1ms/step - loss: 2.1169 - acc: 0.5985 - val_loss: 1.0990 - val_acc: 0.6543\n",
            "Epoch 2/100\n",
            "4847/4847 [==============================] - 3s 559us/step - loss: 0.9226 - acc: 0.6833 - val_loss: 0.8972 - val_acc: 0.6859\n",
            "Epoch 3/100\n",
            "4847/4847 [==============================] - 3s 561us/step - loss: 0.8270 - acc: 0.7015 - val_loss: 0.8554 - val_acc: 0.6952\n",
            "Epoch 4/100\n",
            "4847/4847 [==============================] - 3s 564us/step - loss: 0.7928 - acc: 0.7095 - val_loss: 0.8508 - val_acc: 0.6766\n",
            "Epoch 5/100\n",
            "4847/4847 [==============================] - 3s 562us/step - loss: 0.7634 - acc: 0.7217 - val_loss: 0.9302 - val_acc: 0.6561\n",
            "Epoch 6/100\n",
            "4847/4847 [==============================] - 3s 561us/step - loss: 0.7375 - acc: 0.7436 - val_loss: 0.8562 - val_acc: 0.7045\n",
            "Epoch 7/100\n",
            "4847/4847 [==============================] - 3s 571us/step - loss: 0.7195 - acc: 0.7557 - val_loss: 0.8679 - val_acc: 0.6914\n",
            "Epoch 8/100\n",
            "4847/4847 [==============================] - 3s 561us/step - loss: 0.7113 - acc: 0.7588 - val_loss: 0.8799 - val_acc: 0.6747\n",
            "1347/1347 [==============================] - 0s 232us/step\n",
            "Training on Fold:  10\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_33 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_33 (Embedding)        (None, 25, 300)      1613700     input_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_67 (Conv1D)              (None, 25, 128)      38528       embedding_33[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_68 (Conv1D)              (None, 24, 128)      76928       embedding_33[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_67 (MaxPooling1D) (None, 1, 128)       0           conv1d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_68 (MaxPooling1D) (None, 1, 128)       0           conv1d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 2, 128)       0           max_pooling1d_67[0][0]           \n",
            "                                                                 max_pooling1d_68[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_30 (Flatten)            (None, 256)          0           concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 128)          32896       flatten_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 128)          0           dense_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 3)            387         dropout_30[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,762,439\n",
            "Trainable params: 148,739\n",
            "Non-trainable params: 1,613,700\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4847 samples, validate on 538 samples\n",
            "Epoch 1/100\n",
            "4847/4847 [==============================] - 7s 1ms/step - loss: 2.1158 - acc: 0.5911 - val_loss: 1.0981 - val_acc: 0.6859\n",
            "Epoch 2/100\n",
            "4847/4847 [==============================] - 3s 558us/step - loss: 0.9215 - acc: 0.6792 - val_loss: 0.8917 - val_acc: 0.7026\n",
            "Epoch 3/100\n",
            "4847/4847 [==============================] - 3s 554us/step - loss: 0.8173 - acc: 0.6984 - val_loss: 0.8919 - val_acc: 0.6822\n",
            "Epoch 4/100\n",
            "4847/4847 [==============================] - 3s 554us/step - loss: 0.7875 - acc: 0.7103 - val_loss: 0.8542 - val_acc: 0.6989\n",
            "Epoch 5/100\n",
            "4847/4847 [==============================] - 3s 555us/step - loss: 0.7546 - acc: 0.7231 - val_loss: 0.8749 - val_acc: 0.6822\n",
            "Epoch 6/100\n",
            "4847/4847 [==============================] - 3s 558us/step - loss: 0.7466 - acc: 0.7355 - val_loss: 0.8633 - val_acc: 0.6822\n",
            "Epoch 7/100\n",
            "4847/4847 [==============================] - 3s 554us/step - loss: 0.7188 - acc: 0.7537 - val_loss: 0.8918 - val_acc: 0.6784\n",
            "Epoch 8/100\n",
            "4847/4847 [==============================] - 3s 552us/step - loss: 0.7130 - acc: 0.7528 - val_loss: 0.9103 - val_acc: 0.6989\n",
            "1347/1347 [==============================] - 0s 236us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vT_YIKQN2iEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "103a9e0f-dfa8-4ebb-800f-ec093252e6cd"
      },
      "cell_type": "code",
      "source": [
        "df_cnn = pd.DataFrame(table_cnn, columns=['losses', 'accuracies'], index=range(1,len(table_cnn)+1))\n",
        "display(df_cnn)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>losses</th>\n",
              "      <th>accuracies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.878892</td>\n",
              "      <td>0.687454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.863848</td>\n",
              "      <td>0.678545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.874627</td>\n",
              "      <td>0.680030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.870686</td>\n",
              "      <td>0.659985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.876661</td>\n",
              "      <td>0.674833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.895287</td>\n",
              "      <td>0.654788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.867976</td>\n",
              "      <td>0.678545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.934366</td>\n",
              "      <td>0.683742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.874676</td>\n",
              "      <td>0.665924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.875627</td>\n",
              "      <td>0.668894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      losses  accuracies\n",
              "1   0.878892    0.687454\n",
              "2   0.863848    0.678545\n",
              "3   0.874627    0.680030\n",
              "4   0.870686    0.659985\n",
              "5   0.876661    0.674833\n",
              "6   0.895287    0.654788\n",
              "7   0.867976    0.678545\n",
              "8   0.934366    0.683742\n",
              "9   0.874676    0.665924\n",
              "10  0.875627    0.668894"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vxUM4slvB5FR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}